<div class="profile-card">
  <div class="left-panel">
    <img src="https://github.com/Wal-Liu/Profile/blob/main/avatar/avt.jpg?raw=true" alt="Avatar" class="avatar">
    <h1>Luu Vinh Tuong</h1>
    <p>Final-year Data Engineering student at HCMUTE</p>
    <div class="links">
      <button onclick="goToLink('https://blogs.tuongluu.id.vn')">üåê Personal Blog</button>
      <button onclick="goToLink('CV.html')">üìÑ View CV</button>
    </div>
  </div>

  <div class="right-panel">
    <h2>About Me</h2>
    <p>
      I am <strong>Luu Vinh Tuong</strong>, a final-year student majoring in <strong>Data Engineering</strong> at the
      <em>Ho Chi Minh City University of Technology and Education (HCMUTE)</em>. Passionate about data and technology, I strive to build data systems that enable efficient processing, analysis, and visualization to support informed decision-making.
    </p>

    <h3>Strengths</h3>
    <ul>
      <li>Strong foundation in data processing and analysis across economics, education, and marketing.</li>
      <li>Hands-on experience in small-scale projects involving data pipelines and storage models.</li>
      <li>Quick learner, collaborative, and team-oriented.</li>
      <li>Trained under a curriculum similar to Information Systems with business process understanding.</li>
      <li>Proficient in SQL, Excel, Power BI, Superset, and data storytelling for business decisions.</li>
      <li>Motivated for long-term growth and committed to contributing if given the opportunity.</li>
    </ul>

    <h3>Technical Skills</h3>
    <ul>
      <li><strong>Programming Languages:</strong> Python, SQL, Java, R</li>
      <li><strong>Data Processing Libraries:</strong> numpy, pandas</li>
      <li><strong>Big Data & Frameworks:</strong> Hadoop, Flume, Hive, Kafka, Pig, Spark (PySpark)</li>
      <li><strong>Databases:</strong> SQL Server, MySQL, ClickHouse</li>
      <li><strong>Cloud Platform:</strong> AWS</li>
      <li><strong>Storage:</strong> Data Warehouse, Delta Lake</li>
      <li><strong>Web Scraping:</strong> Selenium, Scrapy</li>
      <li><strong>AI/ML:</strong> Sklearn, TensorFlow 2</li>
      <li><strong>BI Tools:</strong> Superset, Power BI</li>
      <li><strong>Version Control:</strong> Git, GitHub</li>
    </ul>

    <h3>Licenses & Certifications</h3>
    <ul>
      <li>AWS Academy Graduate ‚Äì Cloud Data Pipeline Builder</li>
      <li>AWS Academy Graduate ‚Äì Cloud Developing</li>
      <li>AWS Academy Graduate ‚Äì Web Application Builder</li>
      <li>AWS Academy Graduate ‚Äì Microservices & CI/CD Pipeline Builder</li>
      <li>TOEIC ‚Äì 595 (10/2024)</li>
    </ul>

    <h3>Projects</h3>

    <div class="project">
      <h4>YouTube Watch History Data Pipeline</h4>
      <ul>
        <li>A personal project to collect and process YouTube watch history data from Google Takeout.</li>
        <li>Used PySpark to clean and organize the data efficiently.</li>
        <li>Built a three-layer data storage system to keep data clear and easy to analyze.</li>
        <li>Discovered viewing habits by week and month as well as the most popular content topics.</li>
        <li>Used ClickHouse and Superset to visualize and share data more easily.</li>
      </ul>
    </div>

    <div class="project">
      <h4>Codeforces Contest Streaming and Classroom Analysis</h4>
      <ul>
        <li>Part of a 5-member team building a system to collect and analyze programming contest data from Codeforces.</li>
        <li>Responsible for data processing to track and analyze contests in real-time.</li>
        <li>Performed long-term trend analysis to better understand contestants‚Äô behavior and skill development.</li>
        <li>Helped the team create tailored practice problems to personalize training and improve learning outcomes.</li>
      </ul>
    </div>
    
    <div class="project">
    <h4>T1 Analysis</h4>
    <ul>
      <li>A personal project to learn data analysis and build a dashboard showcasing the performance of my favorite esports team, T1.</li>
      <li>Used Scrapy to collect data from the lol.fandom website, with improvements to scrape data periodically every week to update new information.</li>
      <li>Employed Python to clean, filter, and standardize the collected data.</li>
      <li>Loaded the data into Power BI to create charts and generate useful insights.</li>
      <li>Key insights include the team‚Äôs improving performance toward the end of the year, frequent picks of Azir, Xin Zhao, and Varus in their lineup, and a strong dislike for Maokai and Vi.</li>
    </ul>
  </div>



  </div>

</div>
