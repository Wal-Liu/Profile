<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>CV - Luu Vinh Tuong</title>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/theme/CV/styles.css" />
<script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
</head>
<body>
  <div id="particles-js"></div>
  <main class="cv-wrapper">   
    <h1>Luu Vinh Tuong</h1>
    <p>üìû +84.706.384.806 | ‚úâÔ∏è <a href="mailto:tuongst689@gmail.com">tuongst689@gmail.com</a></p>
    <p>
      <a href="https://github.com/Wal-Liu">GitHub</a> |
      <a href="https://www.facebook.com/vinhtuong.luu.1">Facebook</a> |
      <a href="https://tuongluu.id.vn/">tuongluu.id.vn</a> |
      <a href="https://www.linkedin.com/in/vinhtuongluu689">LinkedIn</a>
    </p>
    <p>A final-year student of Data Engineering passionate about data and technology</p>

    <section>
      <h2>EDUCATION</h2>
        <div class="edu-row">
        <div class="edu-left">
            <strong>HCMC University of Technology and Education</strong><br>
            <em>Data Engineering</em>
        </div>
        <div class="edu-right">
            <strong>1 Vo Van Ngan, Thu Duc, HCMC</strong><br>
            <em>Sep 2022 ‚Äì Expected: 2026</em>
        </div>
        </div>
    </section>

    <div class="section">
    <h2>TECHNICAL SKILLS</h2>
    <ul>
        <li><b>Programming Languages:</b> Python, SQL, Java, R</li>
        <li><b>Big Data & Frameworks:</b> Apache Hadoop, Flume, Hive, Kafka, Pig, Spark</li>
        <li><b>Databases:</b> SQL Server, MySQL, ClickHouse</li>
        <li><b>Cloud Platform:</b> AWS, Azure (Synapse Analytics)</li>
        <li><b>Storage Platforms:</b> Data Warehouse, Data LakeHouse (Delta Lake)</li>
        <li><b>Web Scraping:</b> Python Selenium, Python Scrapy</li>
        <li><b>Python frameworks:</b> PySpark, Scikit-learn, Pandas, NumPy, TensorFlow</li>
        <li><b>Data Visualization:</b> Apache Superset, Power BI</li>
        <li><b>Version Control:</b> Git and GitHub</li>
    </ul>
</div>

<div class="section">
    <h2>LICENSES & CERTIFICATIONS</h2>
    <ul>
        <li>AWS Academy Graduate - AWS Academy Cloud Data Pipeline Builder</li>
        <li>AWS Academy Graduate - AWS Academy Cloud Developing</li>
        <li>AWS Academy Graduate - AWS Academy Cloud Web Application Builder</li>
        <li>AWS Academy Graduate - AWS Academy Microservices and CI/CD Pipeline Builder</li>
    </ul>
</div>

<div class="section">
    <h2>CROSS-INDUSTRY EXPERIENCE</h2>
    <ul>
        <li><b>Marketing:</b>
            <ul>
                <li>Analyzed customer behavior and usage patterns to understand their shopping needs and preferences.</li>
                <li>Segmented customers based on purchasing purposes and spending habits, enabling targeted marketing strategies.</li>
                <li>Explored consumer purchase motivations and identified key factors influencing buying decisions.</li>
            </ul>
        </li>
        <li><b>Finance:</b>
            <ul>
                <li>Monitored financial markets and tracked key market indices for comprehensive market overview.</li>
                <li>Conducted analysis of market trends and macroeconomic indicators to support investment decisions and risk assessment.</li>
            </ul>
        </li>
        <li><b>Logistics:</b>
            <ul>
                <li>Analyzed delivery times, return rates, and transportation costs to optimize supply chain efficiency.</li>
                <li>Applied transit time analysis and cost tracking to improve delivery performance and reduce logistics expenses.</li>
            </ul>
        </li>
        <li><b>Education:</b>
            <ul>
                <li>Analyzed student performance and test results to identify learning gaps and improve teaching effectiveness.</li>
                <li>Developed personalized lesson plans based on data-driven insights to enhance individual learning outcomes.</li>
            </ul>
        </li>
    </ul>
</div>

<div class="section">
    <h2>PROJECTS</h2>
    <div class="project-title"><b>YouTube Watch History Data Pipeline</b></div>
    <ul>
        <li>Collected raw JSON data from Google Takeout, preserving data structure and ensuring data integrity throughout the processing pipeline.</li>
        <li>Designed and implemented a system architecture consisting of Spark Cluster, MinIO + Delta Lake, ClickHouse, and Apache Superset.</li>
        <li><b>Key improvements:</b>
            <ul>
                <li>Spark Cluster: distributed system enabling faster processing of large-scale data compared to traditional Python scripts.</li>
                <li>MinIO + Delta Lake: optimized storage with data compression, version control, and enhanced data security.</li>
                <li>ClickHouse: high-performance OLAP data warehouse supporting real-time data analytics.</li>
                <li>Apache Superset: lightweight, open-source visualization tool with strong integration within the Apache ecosystem.</li>
            </ul>
        </li>
        <li>Performed data integration, cleansing, validation, and transformation entirely using PySpark, achieving efficient big data processing and faster development cycles compared to Java-based Hadoop systems.</li>
        <li>Deployed a 3-layer data architecture (bronze, silver, gold) stored on MinIO and Delta Lake, ensuring clear data layering, maintaining data integrity, and high data readiness for analytics.</li>
        <li>Visualized data at two stages: post-cleaning and after OLAP system construction, providing insights into peak activity times, popular content topics, and viewing habits by week and month.</li>
    </ul>
    <div class="project-title"><b>Codeforces Contest Streaming and Classroom Analysis</b></div>
    <ul>
        <li>Collected submission data from Codeforces API, including all submissions during and outside contest time, stored in structured JSON format with multiple attributes such as userID for comprehensive analysis.</li>
        <li>Cleaned data using Python to filter valid submissions made within contest duration; remaining data used for post-contest exploratory analysis.</li>
        <li>Built a multi-service data processing system:
            <ul>
                <li>Python: ingested submission data and streamed it to Kafka in real-time according to contest timeline.</li>
                <li>Kafka: provided a robust streaming platform ensuring data integrity under high throughput and system load.</li>
                <li>Spark Cluster: processed streaming data for restructuring, cleaning, ETL, and synchronized data between lakehouse and warehouse.</li>
                <li>ClickHouse: high-performance OLAP data warehouse supporting fast analytics on streaming data.</li>
                <li>Grafana: real-time dashboard for monitoring contest submission trends and system status.</li>
                <li>MinIO + Delta Lake: implemented a 3-layer (bronze, silver, gold) storage model optimizing data storage, versioning, and readiness.</li>
                <li>Apache Superset: visualized aggregated contest data post-event, enabling comprehensive reporting and insight extraction.</li>
            </ul>
        </li>
        <li>Conducted data cleaning, exploratory data analysis (EDA), and visualization using Python and matplotlib. Applied regression models with scikit-learn to analyze and predict contest topics and trends.</li>
        <li>Delivered actionable insights on contest progression and individual participant performance; enabled personalized training curriculum development based on user strengths, weaknesses, and popular topics.</li>
    </ul>
</div>

  </main>

  <script>
    particlesJS("particles-js", {
      particles: {
        number: { value: 100 },
        color: { value: "#ffffff" },
        shape: { type: "circle" },
        opacity: { value: 0.2 },
        size: { value: 3 },
        move: {
          enable: true,
          speed: 1,
          direction: "none",
          out_mode: "out"
        }
      },
      interactivity: {
        events: {
          onhover: { enable: false },
          onclick: { enable: false }
        }
      },
      retina_detect: true
    });
  </script>
</body>
</html>
